{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a ><img src=\"https://i.ibb.co/hd2LFFt/Ekran-Resmi-2022-07-20-22-35-22.png\" alt=\"Ekran-Resmi-2022-07-20-22-35-22\" border=\"0\"></a>","metadata":{}},{"cell_type":"code","source":"# Required libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install pygad\n!pip install mplcyberpunk\nimport pygad\nimport numpy\nimport pygad\nimport pygad.nn\nimport pygad.gann\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, classification_report, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-20T19:09:49.184673Z","iopub.execute_input":"2022-07-20T19:09:49.185269Z","iopub.status.idle":"2022-07-20T19:10:11.229737Z","shell.execute_reply.started":"2022-07-20T19:09:49.185234Z","shell.execute_reply":"2022-07-20T19:10:11.228365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Vanishing gradients occur while training deep neural networks using gradient-based optimization methods. It occurs due to the nature of the backpropagation algorithm that is used to train the neural network. In such methods, during each iteration of training each of the neural network's weights receives an update proportional to the partial derivative of the error function with respect to the current weight.\n\n\n![](https://2900157524-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LZMLRvaju5sqPs7pYTX%2F-Lrp-FwxhWogOLC4-q3F%2F-LrPm3c4Pn1RXIZXgXxL%2Fothertechniques.png?generation=1571773560222799&alt=media)\n\n* Deep neural network learning can be formulated as a non-convex optimization problem. Existing optimization algorithms, e.g., Adam, can learn the models fast, but may get stuck in local optima easily.  Adam together with its many optimizer algorithms have been shown to be effective for optimizing a large group of problems. However, for the non-convex objective functions of deep learning models, Adam cannot guarantee to identify the globally optimal solutions, whose iterative updating process may inevitably get stuck in local optima. The performance of Adam is not very robust, which will be greatly degraded for the objective function with non-smooth shape or learning scenarios polluted by noisy data. Furthermore, the distributed computation process of Adam requires heavy synchronization, which may hinder its adoption in large-cluster based distributed computational platforms.\n\n* On the other hand, genetic algorithm (GA), a metaheuristic algorithm inspired by the process of natural selection in evolutionary algorithms, has also been widely used for learning the solutions of many optimization problems. In GA, a population of candidate solutions will be initialized and evolved towards better ones. Several attempts have also been made to use GA for training deep neural network models instead of the gradient descent based methods. GA has demonstrated its outstanding performance in many learning scenarios, like non-convex objective function containing multiple local optima, objective function with non-smooth shape, as well as a large number of parameters and noisy environments. GA also fits the parallel/distributed computing setting very well, whose learning process can be easily deployed on parallel/distributed computing platforms. Meanwhile, compared with Adam, GA may take more rounds to converge in addressing optimization objective functions.\n\n[Reference](https://arxiv.org/pdf/1805.07500.pdf)","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-attack-analysis-prediction-dataset/heart.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T19:10:11.234261Z","iopub.execute_input":"2022-07-20T19:10:11.234667Z","iopub.status.idle":"2022-07-20T19:10:11.260988Z","shell.execute_reply.started":"2022-07-20T19:10:11.234631Z","shell.execute_reply":"2022-07-20T19:10:11.259657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I wouldn't ","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T19:10:11.263119Z","iopub.execute_input":"2022-07-20T19:10:11.263643Z","iopub.status.idle":"2022-07-20T19:10:11.303Z","shell.execute_reply.started":"2022-07-20T19:10:11.263596Z","shell.execute_reply":"2022-07-20T19:10:11.30155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df.output\nX = df.drop(columns=\"output\")\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    stratify = y,\n                                                    test_size = .2,\n                                                    random_state = 42)\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-20T20:36:36.944591Z","iopub.execute_input":"2022-07-20T20:36:36.944997Z","iopub.status.idle":"2022-07-20T20:36:36.967107Z","shell.execute_reply.started":"2022-07-20T20:36:36.944965Z","shell.execute_reply":"2022-07-20T20:36:36.965775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# My keras tool-kit :D\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\nimport tensorflow as tf\nfrom keras.layers import Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom keras import callbacks\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adamax\nimport random\nimport mplcyberpunk\ndef scheduler(epoch, learning_rate):\n    if epoch < 10:\n        return learning_rate\n    else:\n        return learning_rate * tf.math.exp(-0.1)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T19:10:11.332935Z","iopub.execute_input":"2022-07-20T19:10:11.333323Z","iopub.status.idle":"2022-07-20T19:10:11.343322Z","shell.execute_reply.started":"2022-07-20T19:10:11.33328Z","shell.execute_reply":"2022-07-20T19:10:11.342092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nclassifier = tf.keras.Sequential()\ntf.compat.v1.reset_default_graph()\ntf.random.set_seed(0)\nrandom.seed(0)\nnp.random.seed(0)\ninitializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform' , activation = 'relu', input_dim = X_train.shape[1])) \n# Adding the second hidden layer\nclassifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the third hidden layer\nclassifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Compiling the ANN \nclassifier.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n                   loss = 'binary_crossentropy', \n                   metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\n\nr = classifier.fit(X_train, y_train,\n                   validation_data=(X_test,y_test),\n                   callbacks=[callbacks.EarlyStopping(min_delta=0.0001,patience=40,restore_best_weights=True),\n                             tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)],\n                   batch_size=16,\n                   epochs=32)\n\nacc = r.history['accuracy']\nval_acc = r.history['val_accuracy']\nloss = r.history['loss']\nval_loss = r.history['val_loss']\n\nplt.figure(figsize=(12, 6))\nplt.style.use('cyberpunk')\nplt.subplot(1, 2, 1)\nplt.plot(acc, label='Training Acc')\nplt.plot(val_acc, label='Validation Acc')\nplt.title('Training And Validation Acc')\nplt.legend()\nmplcyberpunk.add_glow_effects()\n\n\nplt.subplot(1, 2, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Training And Validation Loss')\nplt.legend()\nmplcyberpunk.add_glow_effects()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T23:19:09.101352Z","iopub.execute_input":"2022-07-20T23:19:09.102003Z","iopub.status.idle":"2022-07-20T23:19:15.046908Z","shell.execute_reply.started":"2022-07-20T23:19:09.101954Z","shell.execute_reply":"2022-07-20T23:19:15.045041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_tr = [1 if each >= 0.5 else 0 for each in classifier.predict(X_train)]\ny_pred_ts = [1 if each >= 0.5 else 0 for each in classifier.predict(X_test)]\n# \nprint('Train Accuracy score: {0:0.2f}'.format(accuracy_score(y_train, y_pred_tr)))\nprint('Train ROC AUC score: {0:0.2f}'.format(roc_auc_score(y_train, y_pred_tr)))\nprint('Test Accuracy score: {0:0.2f}'.format(accuracy_score(y_test, y_pred_ts)))\nprint('Test ROC-AUC score: {0:0.3f}'.format(roc_auc_score(y_test, y_pred_ts)))\nprint(confusion_matrix(y_test,y_pred_ts))\nprint(classification_report(y_test,y_pred_ts))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T23:19:22.107972Z","iopub.execute_input":"2022-07-20T23:19:22.108474Z","iopub.status.idle":"2022-07-20T23:19:22.382369Z","shell.execute_reply.started":"2022-07-20T23:19:22.108436Z","shell.execute_reply":"2022-07-20T23:19:22.380556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step by step genetic algorithm with PyGAD\n### I have to say that this notebook was inspired by Christopher Nolan.\n![](https://cdn.theatlantic.com/thumbor/DG2Xor4Hl_KmZCdCasjGod-MDlk=/190x0:2623x1825/1200x900/media/img/mt/2020/08/MCDINCE_EC040/original.jpg)\n\n## Optimiception\n### It's actually a big dilemma. It isn't alluring to have to optimize the Optimizer. So even though this notebook is the official \"Tutorial of PyGAD\", it's called \"optimiception\" for me.","metadata":{}},{"cell_type":"code","source":"# Inputs\n\narray_X = X_train #.values (Scaler function return np array and pygad working with np.array)\narray_y = y_train.values\narray_X.shape,array_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:32:55.163478Z","iopub.execute_input":"2022-07-20T21:32:55.163977Z","iopub.status.idle":"2022-07-20T21:32:55.17393Z","shell.execute_reply.started":"2022-07-20T21:32:55.163938Z","shell.execute_reply":"2022-07-20T21:32:55.172531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fitness function\n\n* The PyGAD library works by allowing the users to customize the genetic algorithm for their own problems. Because the problems differ in how the fitness values are calculated, then PyGAD allows the user to use a custom function as a maximization fitness function. This function must accept 2 positional parameters representing the following:\n\n    1. The solution.\n    2. The solution index in the population.\n\n\n* The fitness function must return a single number representing the fitness. The higher the fitness value, the better the solution.\n\n* Here is the implementation of the fitness function for training a neural network. It uses the `pygad.nn.predict()` function to predict the class labels based on the current solution’s weights. The `pygad.nn.predict()` function uses the trained weights available in the trained_weights attribute of each layer of the network for making predictions.\n\n* Based on such predictions, the classification accuracy is calculated. This accuracy is used as the fitness value of the solution. Finally, the fitness value is returned.","metadata":{}},{"cell_type":"code","source":"# Fitness function ``\n\ndef fitness_func(solution, sol_idx):\n    global GANN_instance, data_inputs, data_outputs\n    predictions = pygad.nn.predict(last_layer=GANN_instance.population_networks[sol_idx],\n                                   data_inputs=data_inputs)\n    correct_predictions = numpy.where(predictions == data_outputs)[0].size\n    solution_fitness = (correct_predictions/data_outputs.size)*100\n\n    return solution_fitness","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:32:56.251971Z","iopub.execute_input":"2022-07-20T21:32:56.253056Z","iopub.status.idle":"2022-07-20T21:32:56.260063Z","shell.execute_reply.started":"2022-07-20T21:32:56.252999Z","shell.execute_reply":"2022-07-20T21:32:56.259183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callback generation\n\n* After each generation of the genetic algorithm, the fitness function will be called to calculate the fitness value of each solution. Within the fitness function, the `pygad.nn.predict()` function is used for predicting the outputs based on the current solution’s trained_weights attribute. Thus, it is required that such an attribute is updated by weights evolved by the genetic algorithm after each generation.\n\n* This callback function can be used to update the trained_weights attribute of layers of each network in the population.\n\n* Here is the implementation for a function that updates the trained_weights attribute of the layers of the population networks.\n\n* It works by converting the current population from the vector form to the matric form using the `pygad.gann.population_as_matrices()` function. It accepts the population as vectors and returns it as matrices.\n\n* The population matrices are then passed to the `update_population_trained_weights()` method in the pygad.gann module to update the trained_weights attribute of all layers for all solutions within the population.\n\n#### My contribution \n* I creating `verbose` function additionally, because\n* I think the biggest handicap of this library is that it returns to all generations and their fitness result. Sometimes I create 10000 generations and get distracted by the generation's returns.","metadata":{}},{"cell_type":"code","source":"# First generation must came from zero.\nlast_fitness = 0\n\ndef callback_generation(ga_instance):\n    global GANN_instance, last_fitness\n\n    population_matrices = pygad.gann.population_as_matrices(population_networks=GANN_instance.population_networks,\n                                                            population_vectors=ga_instance.population)\n\n    GANN_instance.update_population_trained_weights(population_trained_weights=population_matrices)\n    if ga_instance.generations_completed % verbose == 0:\n        print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n        print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n        print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n\n    last_fitness = ga_instance.best_solution()[1].copy();\n\n# Holds the fitness value of the previous generation. We use this on the callback function\n","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:33:00.009336Z","iopub.execute_input":"2022-07-20T21:33:00.010242Z","iopub.status.idle":"2022-07-20T21:33:00.020474Z","shell.execute_reply.started":"2022-07-20T21:33:00.010179Z","shell.execute_reply":"2022-07-20T21:33:00.019361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the Training Data\n","metadata":{}},{"cell_type":"code","source":"# Prepare to data\n\n#Before building and training neural networks, the training data (input and output) is to be prepared. \n# The inputs and the outputs of the training data are NumPy arrays.\n# Reading the input data.\ndata_inputs = array_X\n# Optional step of filtering the input data using the standard deviation.\n#features_STDs = numpy.std(a=data_inputs, axis=0)\n#data_inputs = data_inputs[:, features_STDs>50]\n\n# Reading the output data.\ndata_outputs = array_y\n\n# The length of the input vector for each sample (i.e. number of neurons in the input layer).\nnum_inputs = data_inputs.shape[1]\n\n# The number of neurons in the output layer (i.e. number of classes).\n# For the XOR models, there are 2 classes and thus their labels are 0 and 1. \n# The num_classes variable is assigned to 2.\nnum_classes = 2","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:33:01.468366Z","iopub.execute_input":"2022-07-20T21:33:01.468817Z","iopub.status.idle":"2022-07-20T21:33:01.476512Z","shell.execute_reply.started":"2022-07-20T21:33:01.468781Z","shell.execute_reply":"2022-07-20T21:33:01.474491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating an initial population of neural networks.","metadata":{}},{"cell_type":"code","source":"# The return of the initial_population() function holds references to the networks, not their weights. Using such references, the weights of all networks can be fetched.\n\nnum_solutions = 16\n# A solution or a network can be used interchangeably.\n# Number of solutions like as chromosomes.\nGANN_instance = pygad.gann.GANN(num_solutions=num_solutions,\n                                # chromosomes\n                                num_neurons_input=num_inputs,\n                                # input layer\n                                #num_neurons_output=1,\n                                # Number of neurons in the output layer.\n                                num_neurons_hidden_layers=[8,16,32],\n                                # I have comparing with above ANN, you can changing array.\n                                # While each number in the array represents the hidden layers from left to right, \n                                # the values they take represent the number of nodes.\n                                # If empty [], then no hidden layers are used. \n                                # For each int value it holds, then a hidden layer is created with a number of hidden neurons specified by the corresponding int value. \n                                # For example, num_neurons_hidden_layers=[10] creates a single hidden layer with 10 neurons. \n                                # num_neurons_hidden_layers=[10, 5] creates 2 hidden layers with 10 neurons for the first and 5 neurons for the second hidden layer.\n                                num_neurons_output=num_classes,\n                                # output layer\n                                hidden_activations=[\"relu\", \"relu\",\"relu\"],\n                                # Each array element is the activation function of \n                                # the hidden layer at the same index.\n                                # relu, sigmoid and softmax avaible.\n                                output_activation=\"sigmoid\"\n                                #  here is important because of if num_classes bigger than 2\n                                # output_activation must be \"softmax\"\n                               )\n\n# population does not hold the numerical weights of the network\n# instead it holds a list of references to each last layer of each network (i.e. solution) in the population. \n# A solution or a network can be used interchangeably.\n# If there is a population with 3 solutions (i.e. networks), then the population is a list with 3 elements. \n# Each element is a reference to the last layer of each network. \n# Using such a reference, all details of the network can be accessed.\n\n# let's create first population\npopulation_vectors = pygad.gann.population_as_vectors(population_networks=GANN_instance.population_networks)\n\n# To prepare the initial population, there are 2 ways:\n# 1) Prepare it yourself and pass it to the initial_population parameter. \n# This way is useful when the user wants to start the genetic algorithm with a custom initial population.\n# 2) Assign valid integer values to the sol_per_pop and num_genes parameters. \n# If the initial_population parameter exists, then the sol_per_pop and num_genes parameters are useless.\n# Don't forget your root!\ninitial_population = population_vectors.copy()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:35:40.864827Z","iopub.execute_input":"2022-07-20T21:35:40.865348Z","iopub.status.idle":"2022-07-20T21:35:40.881833Z","shell.execute_reply.started":"2022-07-20T21:35:40.865304Z","shell.execute_reply":"2022-07-20T21:35:40.880358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Here set-up the evolution strategy","metadata":{}},{"cell_type":"code","source":"\n# Number of solutions to be selected as parents in the mating pool.\n\nnum_parents_mating = 4\n\n# Number of generations\n\nnum_generations = 1000 # Number of generations","metadata":{"execution":{"iopub.status.busy":"2022-07-20T22:55:18.718531Z","iopub.execute_input":"2022-07-20T22:55:18.718975Z","iopub.status.idle":"2022-07-20T22:55:18.723722Z","shell.execute_reply.started":"2022-07-20T22:55:18.718942Z","shell.execute_reply":"2022-07-20T22:55:18.722934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In addition\n\n* The part that I had the most difficulty understanding was this variable. I don't know why I confused it with num_solution. That's why I wanted to elaborate on this part further.\n* num_solution parameters mean creating a different population with the same architecture, with this reason bigger num_solution maybe find a better result but duration longer.\n* The best method would be to narrate it by looking at the schematic of the operations. \n\n\n![](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-022-05335-3/MediaObjects/41598_2022_5335_Fig1_HTML.png?as=webp)\n[Source of image](https://www.nature.com/articles/s41598-022-05335-3/figures/1)\n\n","metadata":{}},{"cell_type":"markdown","source":"### Best point about population and parent\n* It was enlightening for me to learn that chromosome is synonymous with parent. \n* Because in biology, it includes parent chromosomes, so it makes more sense to me that it was `synonymous` with population rather than chromosome.\n* In mammals, fertilization (sexual reproduction) is defined as the union of two germ cells, egg (female) and sperm (male), whereby the somatic chromosome number is restored and the resulting offspring exhibit characteristics of their parents. \n\n\n* Male and female gametes fuse and recombine inherited traits of the two parents to produce individuals with novel assortments of genes. Sexual reproduction, as opposed to asexual reproduction, a process that gives rise to offspring genetically identical to the parent organism, has great advantages. Consequently, a vast majority of plants and animals have adopted it.\n\n[Reference](https://link.springer.com/referenceworkentry/10.1007/3-540-29623-9_3270#Fig1_3270)\n\n\n* When I think of the following as a dictionary from genetic algorithm to biology:\n    \n    * Population is male or female\n    * Parents is gametes\n        \n* Although mutations rarely occur during or after fertilization, most of them occur in the meiosis stage with crossing over.\n###  Real life is not elitist, it is generally randomly. \n* I must stop thinking with medical knowledge :D\n\n\n\n![](https://apbionotebook.files.wordpress.com/2014/02/human-life-cycle.jpg)\n\n\n## Parent Selection and Mating Pool in Genetic Algorithms.\n\n","metadata":{}},{"cell_type":"code","source":"parent_selection_type = \"tournament\" # Type of parent selection.\nkeep_parents = -1 \n# Number of parents to keep in the next population. \n# -1 means keep all parents and 0 means keep nothing.\n\n####-sss (for steady state selection)\n####-rws (for roulette wheel selection)\n####-sus (for stochastic universal selection)\n####-rank (for rank selection)\n####-random (for random selection)\n####-tournament (for tournament selection),\nK_tournament=4 # Just tournament\n","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:37:38.633219Z","iopub.execute_input":"2022-07-20T21:37:38.634037Z","iopub.status.idle":"2022-07-20T21:37:38.640961Z","shell.execute_reply.started":"2022-07-20T21:37:38.633978Z","shell.execute_reply":"2022-07-20T21:37:38.639581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Parent Selection is the process of selecting parents which mate and recombine to create off-springs for the next generation. Parent selection is very crucial to the convergence rate of the GA as good parents drive individuals to a better and fitter solutions.\n\n* However, care should be taken to prevent one extremely fit solution from taking over the entire population in a few generations, as this leads to the solutions being close to one another in the solution space thereby leading to a loss of diversity. Maintaining good diversity in the population is extremely crucial for the success of a GA. This taking up of the entire population by one extremely fit solution is known as premature convergence and is an undesirable condition in a GA.\n\n\n## Steady-state selection (`sss`, default)\n* Usually, the run of a genetic algorithm is divided into generations - at each generation, the result of the selection and reproduction process replaces all (or at least most) of the population; only children survive. In a steady state genetic algorithm, however, only a few individuals are replaced at a time, meaning most of the individuals will carry out to the next generation; there is no generation per se.\n\n* There are multiple implementations. For example, in one variant, parents are selected using e.g. tournament selection. Then, children and parents are compared (based on the fitness value), and only the best ones are put back in the population.\n\n* In another variant, the best chromosomes are selected for reproduction, and their offsprings will replace the worst individuals.\n\n* SSS is the only algorithm of this type offered by PyGAD at the time of writing.\n\n## Roulette wheel selection (`rws`)\n* I mentioned [previously](https://www.kaggle.com/code/zzettrkalpakbal/tutorial-of-genetic-algorithm) notebook.\n* This is a widely used and most efficient method for selecting parents. We all know how the roulette wheel works in casinos, drop the ball, spin the wheel, and wait till the wheel stops to see which pot the ball falls in. \n![](https://miro.medium.com/max/1400/1*7sMoHK26bY2O-NzZBGqSmw.png)\n* The only difference between the casino roulette wheel and the roulette wheel method for parent selection is that in the casino roulette wheel, each pot has an equal probability of holding the ball when the wheel stops rotating. However, here we define the probability for each pot(individual of the population). The probability of each individual is called the fitness of the individual.\n![](https://miro.medium.com/max/1400/0*1KZQfvbi5T2h_rKk.png)\n* We have four parents P1, P2, P3, and P4, with the probability of being selected for breeding 0.1, 0.2, 0.3, 0.4, respectively. The arrow is fixed at a place, and the wheel is rotated. When the wheel stops rotating, the parent where the arrow points to is chosen for breeding—the greater the probability larger the area on the wheel, leading to a higher probability of being selected.\n* Now, how do we implement the roulette wheel programmatically? \n* We open the wheel into a uniform line and divide the line into the number of parents in the population, and each parent occupies the space on the line equal to its probability of being selected, and each cut point is the cumulative sum of probability. Generating a random number between 0 and 1 will act like the arrow that selects the parent for breeding. Here, the random number is 0.28; hence the winner is P2.\n\n![](https://miro.medium.com/max/1400/0*RXV2IqV1sT9NapGq.jpeg)\n\n* To make it even simpler, we calculate each parent’s probability’s cumulative sum, multiply its sum with a randomly generated number. Then get the index of the first parent whose cumulative value is greater than the random number. For example, P1 has a cumulative value of 0.1, P2 has 0.3, P3 has 0.6, and P4 has 1. If the random number generated is 0.28, then the first parent whose cumulative value is greater than 0.28 is P2 hence the winning parent for breeding. \n\n\n### Stochastic universal sampling selection (`sus`)\n* SUS is another variant of fitness proportionate selection which exhibits no bias and minimal spread.\n\n* The same roulette wheel is used than in RWS, with the same proportions, but instead of using a single selection point and turning the roulette wheel again and again until all needed individuals have been selected, here all the parents are selected at once. For that, the wheel is spun only once, and multiple selection points spaced evenly around the wheel determine which individuals are drawn.\n\n![](https://www.tutorialspoint.com/genetic_algorithms/images/sus.jpg)\n\n* This gives weaker members of the population (according to their fitness) a chance to be chosen, and also encourages the highly fit to be chosen at least once.\n\n* In `rws`, one parent is chosen at a time, so the selection bias of the parent with the highest portion increases each time. I think it protects the model from being overfitted because `sus` will select the parents at once.\n\n* It is to be noted that fitness proportionate selection methods don’t work for cases where the fitness can take a negative value.\n\n### Tournament selection (`tournament`)\n* Tournament selection works by selecting `K` (tournament size) individuals randomly (tournament), and pick the fittest of them (the winner) for breeding.\n\n* The selection pressure depends on `K`: the largest `K`, the stronger the pressure, as weaker individuals will have more adversaries, and thus a higher chance of losing.\n\n* In PyGAD, the tournament size is controlled by the `K_tournament` parameter.\n    * In case that the parent selection type is tournament, the `K_tournament` specifies the number of parents participating in the tournament selection. It defaults to `3`.\n\n* Tournament Selection is also extremely popular in literature as it can even work with negative fitness values.\n\n![](https://www.tutorialspoint.com/genetic_algorithms/images/tournament_selection.jpg)\n\n### Rank Selection (`rank`)\n* Rank Selection also works with negative fitness values and is mostly used when the individuals in the population have very close fitness values (this happens usually at the end of the run). This leads to each individual having an almost equal share of the pie (like in case of fitness proportionate selection) as shown in the following image and hence each individual no matter how fit relative to each other has an approximately same probability of getting selected as a parent. This in turn leads to a loss in the selection pressure towards fitter individuals, making the GA to make poor parent selections in such situations.\n\n* In this, we remove the concept of a fitness value while selecting a parent. However, every individual in the population is ranked according to their fitness. The selection of the parents depends on the rank of each individual and not the fitness. The higher ranked individuals are preferred more than the lower ranked ones.\n\n* That is, we first rank the individuals from highest to `lowest fitness value (i=1..N)`, assign the probabilities of being chosen based on `sum of fitness values / i`, and finally spin the wheel.\n\n* Note that this would then be a linear rank selection: the ranks are in a linear progression. There are other schemes of rank selection, for example exponential.\n\n![](https://www.tutorialspoint.com/genetic_algorithms/images/rank_selection.jpg)\n\n### Random selection (`random`)\nThe name says it all: the parents are randomly selected from the population, irrelevant of their fitness.\n\n\n#### References:\n[Tutorialspoint](https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm#:~:text=Parent%20Selection%20is%20the%20process,a%20better%20and%20fitter%20solutions.)\n\n\n[dev.to](https://dev.to/derlin/genetic-algorithms-with-pygad-selection-crossover-mutation-14mn)\n\n\n[pubs.towards.ai](https://pub.towardsai.net/genetic-algorithm-ga-introduction-with-example-code-e59f9bc58eaf)","metadata":{}},{"cell_type":"markdown","source":"## Crossover and mutation\n\n","metadata":{}},{"cell_type":"code","source":"crossover_type = \"uniform\" # Type of the crossover operator.\n\n####-single_point (for single point crossover)\n####-two_points (for two points crossover)\n####-uniform (for uniform crossover)\n####-scattered (for scattered crossover)\n\ncrossover_probability= 1 #arange(0,1)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:50:50.277247Z","iopub.execute_input":"2022-07-20T21:50:50.278117Z","iopub.status.idle":"2022-07-20T21:50:50.284719Z","shell.execute_reply.started":"2022-07-20T21:50:50.27806Z","shell.execute_reply":"2022-07-20T21:50:50.28353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Crossover algorithms\n* The crossover_type defines how children are generated from the selected parents; in other words, how the reproduction works. At the time of writing, PyGAD supports 4 algorithms:\n\n    * 1. crossover_type=\"single_point\": Type of the crossover operation. Supported types are single_point (for single-point crossover), \n    * 2. two_points (for two points crossover), \n    * 3. uniform (for uniform crossover) \n    * 4. scattered (for scattered crossover).\n\n### single-point crossover (`single_point`, `default`)\n* The breeding works by selecting an index randomly (crossover point). All genes to the right of that point are then swapped between the two parent chromosomes. This results in two offsprings, each carrying some genetic information from both parents.\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190620121215/singleCrossover-2.png)\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190620121247/singleCrossover1-2.png)\n\n### two-points crossover (`two_points`)\n* `K-point` crossover works the same as single-point crossover, but instead of one crossover point, we have many. PyGAD supports only `K`=2. In this case, the genes in between the two points are swapped between the parents, yielding again two new offsprings.\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190620121313/twopointCrossover-2.png)\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190620121338/twopointCrossover1-2.png)\n\n### uniform crossover (`uniform`)\n* In a uniform crossover, we essentially flip a coin to decide wether each gene is left untouched, or taken from the other parent. In other words, each gene is chosen from either parent with equal probability. The technique is repeated for each new child.\n\n* Note that in some variants (but not PyGAD), it is possible to bias the coin towards one parent, resulting in children inheriting more from it.\n\n![](https://media.geeksforgeeks.org/wp-content/uploads/20190620121403/unifromCrossover-2.png)\n\n### scattered crossover (`scattered`)\nIn scattered crossover, a random binary vector the size of the chromosomes is generated.\nThe genes of the new child are taken from one parent when its index in the binary vector equals `0`, and the other parent when it equals `1`.\n\n![](https://res.cloudinary.com/practicaldev/image/fetch/s--VA16xe6A--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://www.researchgate.net/profile/Jordi-Roger-Riba/publication/276383889/figure/fig3/AS:391860968280066%401470438343480/Scattered-crossover-representation-when-dealing-with-ten-input-ariables.png)\n\n### Crossover probability \n* `crossover_probability`=None : The probability of selecting a parent for applying the crossover operation. Its value must be between 0.0 and 1.0 inclusive. For each parent, a random value between 0.0 and 1.0 is generated. If this random value is less than or equal to the value assigned to the crossover_probability parameter, then the parent is selected. \n\n\n\n\nReferences:\n[Geeks](https://www.geeksforgeeks.org/crossover-in-genetic-algorithm/)","metadata":{}},{"cell_type":"markdown","source":"## Mutation types","metadata":{}},{"cell_type":"code","source":"mutation_percent_genes = 10 \n# Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists.\n# If you want use to adaptive, you can setting parameter on the ga_instance parameter.\n# I cant running with my dataset but I added example code for adaptive mutation below.\nmutation_type = \"random\" # Type of the mutation operator.\n\n\n####-random (for random mutation)\n####-swap (for swap mutation)\n####-inversion (for inversion mutation)\n####-scramble (for scramble mutation)\n####-adaptive (for adaptive mutation)\n                    # If you selecting to adaptive paramter you must already usi this below parameters.\n                    #mutation_probability=mutation_probability,\n                    #mutation_num_genes=mutation_num_genes","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:45:45.801719Z","iopub.execute_input":"2022-07-20T21:45:45.802192Z","iopub.status.idle":"2022-07-20T21:45:45.808994Z","shell.execute_reply.started":"2022-07-20T21:45:45.802129Z","shell.execute_reply":"2022-07-20T21:45:45.807658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The mutation_types defines the mutation algorithm, that is which transformations are made to the children. It is possible to pass None, meaning no mutation.\n    * At the time of writing, PyGAD supports 5 algorithms:\n\n        * mutation_type= Type of the mutation operation. \n            * `random` (for random mutation), \n            * `swap` (for swap mutation), \n            * `inversion` (for inversion mutation), \n            * `scramble` (for scramble mutation), \n            * `adaptive` (for adaptive mutation). \n            * It defaults to random.\n* The actual number of mutations applied to each child is controlled by the `mutation_num_genes`/`mutation_probability`/`mutation_percent_genes` parameters.\n\n* Here is the gist:\n\n    * `random` (default): a random value from the set of permissible values is assigned to a randomly chosen gene;\n        * `mutation_by_replacement`=False: \n          * An optional bool parameter. It works only when the selected type of mutation is random (`mutation_type`=\"random\"). In this case, `mutation_by_replacement=True` means replace the gene by the randomly generated value. If `False`, then it has no effect and `random` mutation works by adding the `random` value to the gene. \n\n        * `random_mutation_min_val`=-1.0: \n            * For random mutation, the `random_mutation_min_val` parameter specifies the start value of the range from which a random value is selected to be added to the gene. It defaults to -1. This parameter has no action if `mutation_type` is None.\n        * `random_mutation_max_val`=1.0: \n            * For random mutation, the `random_mutation_max_val` parameter specifies the end value of the range from which a `random` value is selected to be added to the gene. It defaults to +1. This parameter has no action if `mutation_type` is None.\n        * `gene_space`=None: \n            * It is used to specify the possible values for each gene in case the user wants to restrict the gene values. It is useful if the gene space is restricted to a certain range or to discrete values. It accepts a list, tuple, range, or numpy.ndarray. When all genes have the same global space, specify their values as a list/tuple/range/numpy.ndarray. For example, gene_space = [0.3, 5.2, -4, 8] restricts the gene values to the 4 specified values. If each gene has its own space, then the gene_space parameter can be nested like [[0.4, -5], [0.5, -3.2, 8.2, -9], ...] where the first sublist determines the values for the first gene, the second sublist for the second gene, and so on. If the nested list/tuple has a None value, then the gene’s initial value is selected randomly from the range specified by the 2 parameters `init_range_low` and `init_range_high` and its mutation value is selected `randomly` from the range specified by the 2 parameters `random_mutation_min_val` and `random_mutation_max_val`\n            \n            \n            \n![](https://media.geeksforgeeks.org/wp-content/uploads/genetic-algorithm2.png)    \n    ","metadata":{}},{"cell_type":"markdown","source":"* `swap`: two genes are selected randomly and their values swapped;\n\n    \n![](https://www.researchgate.net/profile/Omayma-El-Majdoubi-2/publication/342712750/figure/fig3/AS:910283321126913@1594039864690/Mutation-operator-The-genetic-algorithm-is-an-evolutionary-metaheuristic-It-is-an.ppm)      ","metadata":{}},{"cell_type":"markdown","source":"* `inversion`: a consecutive sequence of genes is selected, and their values reversed;\n\n\n\n<a ><img src=\"https://i.ibb.co/NCZd34J/Inversion-mutation-operator-413-Hybrid-Bees-Algorithm-The-bees-algorithm-BA-is-a.jpg\" alt=\"Inversion-mutation-operator-413-Hybrid-Bees-Algorithm-The-bees-algorithm-BA-is-a\" border=\"0\"></a>","metadata":{}},{"cell_type":"markdown","source":"* `scramble`: as for inversion, a consecutive sequence of genes is selected, but this time their values are randomly shuffled;\n\n\n![](https://www.researchgate.net/publication/329265512/figure/fig11/AS:941473017118758@1601476067356/Scramble-mutation-for-scheduling-the-jobs_W640.jpg)\n","metadata":{}},{"cell_type":"markdown","source":"### Adaptive mutation\n\n* `adaptive`: apply a number of random mutations relative to the fitness of the individual. That is, children with a high fitness value will undergo less mutations than children with low fitness values. The actual variations are under your control, by specifying a lower and upper bound instead of a single value for `mutation_num_genes`/`mutation_probability`/`mutation_percent_genes`. The idea behind it is straight-forward: altering good chromosomes has a high chance of degrading them, and vice-versa.\n\n    * `mutation_probability`=None:\n    \n        * The probability of selecting a gene for applying the mutation operation. Its value must be between 0.0 and 1.0 inclusive. For each gene in a solution, a random value between 0.0 and 1.0 is generated. If this random value is less than or equal to the value assigned to the mutation_probability parameter, then the gene is selected. If this parameter exists, then there is no need for the 2 parameters `mutation_percent_genes` and `mutation_num_genes`.\n        \n    * `mutation_percent_genes`=\"default\": \n    \n         * Percentage of genes to mutate. It defaults to the string `\"default\"` which is later translated into the integer `10 which means 10%` of the genes will be mutated. `It must be >0 and <=100.` Out of this percentage, the number of genes to mutate is deduced which is assigned to the `mutation_num_genes parameter`. `The mutation_percent_genes` parameter has no action if `mutation_probability or mutation_num_genes exist`. \n         \n     * `mutation_num_genes`=None: \n     \n         *  Number of genes to mutate which defaults to None meaning that no number is specified. The `mutation_num_genes parameter` has no action if the parameter `mutation_probability` exists. \n         \n* When `adaptive` mutation is used, then the value assigned to any of the 3 parameters can be of any of these data types:\n    * `list`\n    \n    * `tuple`\n    \n    * `numpy.ndarray`\n\n* Whatever the data type used, the length of the `list`, `tuple`, or the `numpy.ndarray` must be exactly `2`. That is there are just 2 values:\n    * 1. The first value is the mutation rate for the low-quality solutions.\n    * 2. The second value is the mutation rate for the low-quality solutions.\n        * PyGAD expects that the first value is higher than the second value and thus a warning is printed in case the first value is lower than the second one.\n            \n            * `mutation_probability = [0.25, 0.1] or (0.35, 0.17) or numpy.array([0.15, 0.05])`\n            \n            * `mutation_num_genes = [4, 2] or (3, 1) or  numpy.array([7, 2])`\n            \n            * `mutation_percent_genes = [25, 12] or (15, 8) or numpy.array([21, 13])`\n\n* Assume that the average fitness is 12 and the fitness values of 2 solutions are 15 and 7. If the mutation probabilities are specified as follows:\n    *  `mutation_probability = [0.25, 0.1]`\n\n    * Then the mutation probability of the first solution is 0.1 because its fitness is 15 which is higher than the average fitness 12. The mutation probability of the second solution is 0.25 because its fitness is 7 which is lower than the average fitness 12.\n        * *for mor information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#use-adaptive-mutation-in-pygad*\n\n","metadata":{}},{"cell_type":"code","source":"verbose = 100\nga_instance = pygad.GA(num_generations=num_generations,\n                       num_parents_mating=num_parents_mating,\n                       initial_population=initial_population,\n                       fitness_func=fitness_func,\n                       # mutation_percent_genes=mutation_percent_genes,\n                       # When the set adaptive mutation\n                       #mutation_percent_genes= (25,12),\n                       #mutation_probability=(0.35,0.12),\n                       #mutation_num_genes=(4,2),\n                       #sol_per_pop=20,\n                       #num_genes=len(array_X),\n                       # When the set tournament selection\n                       K_tournament=K_tournament,\n                       parent_selection_type=parent_selection_type,\n                       crossover_probability=crossover_probability,\n                       crossover_type=crossover_type,\n                       mutation_type=mutation_type,\n                       keep_parents=keep_parents,\n                       on_generation=callback_generation)\n\n\n# By calling the run() method from the pygad.GA instance, \n# the genetic algorithm will iterate through the number of generations specified in its num_generations parameter.\nga_instance.run()\n\n#Plot the Fitness Values\n#After the run() method completes, the plot_fitness() method can be called to show how the fitness values evolve by generation. \n# A fitness value (i.e. accuracy) of 100 is reached after around 180 generations.\n# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\nga_instance.plot_fitness()\n\n# Returning the details of the best solution.\nsolution, solution_fitness, solution_idx = ga_instance.best_solution()\n#print(\"Parameters of the best solution : {solution}\".format(solution=solution))\nprint(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\nprint(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n\nif ga_instance.best_solution_generation != -1:\n    print(\"Best fitness value reached after {best_solution_generation} generations.\".format(best_solution_generation=ga_instance.best_solution_generation))\n\n# Predicting the outputs of the data using the best solution.\npredictions = pygad.nn.predict(last_layer=GANN_instance.population_networks[solution_idx],\n                               data_inputs=data_inputs)\n#print(\"Predictions of the trained network : {predictions}\".format(predictions=predictions))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T22:55:31.189317Z","iopub.execute_input":"2022-07-20T22:55:31.190122Z","iopub.status.idle":"2022-07-20T23:00:32.56277Z","shell.execute_reply.started":"2022-07-20T22:55:31.190077Z","shell.execute_reply":"2022-07-20T23:00:32.561371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Calculating Some Statistics\nBased on the predictions the network made, some statistics can be calculated such as the number of correct and wrong predictions in addition to the classification accuracy.","metadata":{}},{"cell_type":"code","source":"# Calculating some statistics\nnum_wrong = numpy.where(predictions != data_outputs)[0]\nnum_correct = data_outputs.size - num_wrong.size\naccuracy = 100 * (num_correct/data_outputs.size)\nprint(\"Number of correct classifications : {num_correct}.\".format(num_correct=num_correct))\nprint(\"Number of wrong classifications : {num_wrong}.\".format(num_wrong=num_wrong.size))\nprint(\"Classification accuracy : {accuracy}.\".format(accuracy=accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T23:02:06.930077Z","iopub.execute_input":"2022-07-20T23:02:06.930581Z","iopub.status.idle":"2022-07-20T23:02:06.93928Z","shell.execute_reply.started":"2022-07-20T23:02:06.93054Z","shell.execute_reply":"2022-07-20T23:02:06.937933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_tr = pygad.nn.predict(last_layer=GANN_instance.population_networks[solution_idx],\n                               data_inputs=X_train)\ny_pred_ts = pygad.nn.predict(last_layer=GANN_instance.population_networks[solution_idx],\n                               data_inputs=X_test)\n\n\nprint('Train Accuracy score: {0:0.4f}'.format(accuracy_score(y_train, y_pred_tr)))\nprint('Train ROC AUC score: {0:0.4f}'.format(roc_auc_score(y_train, y_pred_tr)))\nprint('Test Accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred_ts)))\nprint('Test ROC-AUC score: {0:0.4f}'.format(roc_auc_score(y_test, y_pred_ts)))\nprint(confusion_matrix(y_test,y_pred_ts))\nprint(classification_report(y_test,y_pred_ts))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T23:02:10.04352Z","iopub.execute_input":"2022-07-20T23:02:10.043942Z","iopub.status.idle":"2022-07-20T23:02:10.081411Z","shell.execute_reply.started":"2022-07-20T23:02:10.04391Z","shell.execute_reply":"2022-07-20T23:02:10.080206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PyGAD: \n* Train Accuracy score: 0.8967\n* Train ROC AUC score: 0.8955\n* Test Accuracy score: 0.8033\n* Test ROC-AUC score: 0.7992\n\n## Keras:\n* Train Accuracy score: 0.90\n* Train ROC AUC score: 0.90\n* Test Accuracy score: 0.75\n* Test ROC-AUC score: 0.746\n\n\n\n### Summary\n* Maybe I could preprocess the data.\n* Maybe I could use bigger data.\n* I could try a different optimizer for Keras. Well then, we could further optimize the genetic algorithm. :D\n* My goal here was to create a tutorial. Thank you if you've read this far. Thanks to [Ahmed Fawzy GAD](https://www.linkedin.com/in/ahmedfgad/) for developing this library myself.\n* See you in different notebooks.","metadata":{}},{"cell_type":"markdown","source":"## Adaptive mutation example","metadata":{}},{"cell_type":"code","source":"%%time\nimport pygad\nimport numpy\n\nfunction_inputs = np.random.randn(40) # Function inputs.\ndesired_output = 44 # Function output.\n\ndef fitness_func_adaptive(solution, solution_idx):\n    # The fitness function calulates the sum of products between each input and its corresponding weight.\n    output = numpy.sum(solution*function_inputs)\n    # The value 0.000001 is used to avoid the Inf value when the denominator numpy.abs(output - desired_output) is 0.0.\n    fitness = 1.0 / (numpy.abs(output - desired_output) + 0.000001)\n    return fitness\n\n# Creating an instance of the GA class inside the ga module. Some parameters are initialized within the constructor.\nga_instance = pygad.GA(num_generations=200,\n                       fitness_func=fitness_func_adaptive,\n                       num_parents_mating=10,\n                       mutation_percent_genes= (25,12),\n                       mutation_probability=(0.35,0.12),\n                       mutation_num_genes=(4,2),\n                       sol_per_pop=200,\n                       num_genes=len(function_inputs),\n                       mutation_type=\"adaptive\")\n\n# Running the GA to optimize the parameters of the function.\nga_instance.run()\n\nga_instance.plot_fitness(title=\"PyGAD with Adaptive Mutation\", linewidth=5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:09:10.530562Z","iopub.execute_input":"2022-07-20T21:09:10.5314Z","iopub.status.idle":"2022-07-20T21:09:19.178958Z","shell.execute_reply.started":"2022-07-20T21:09:10.531299Z","shell.execute_reply":"2022-07-20T21:09:19.17742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nga_instance = pygad.GA(num_generations=200,\n                       fitness_func=fitness_func_adaptive,\n                       num_parents_mating=10,\n                       mutation_percent_genes= 10,\n                       sol_per_pop=200,\n                       num_genes=len(function_inputs),\n                       mutation_type=\"random\")\n\n# Running the GA to optimize the parameters of the function.\nga_instance.run()\n\nga_instance.plot_fitness(title=\"PyGAD with Adaptive Mutation\", linewidth=5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T21:09:27.40665Z","iopub.execute_input":"2022-07-20T21:09:27.407045Z","iopub.status.idle":"2022-07-20T21:09:32.432413Z","shell.execute_reply.started":"2022-07-20T21:09:27.407017Z","shell.execute_reply":"2022-07-20T21:09:32.430641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Other informative pages](https://www.generativedesign.org/02-deeper-dive/02-04_genetic-algorithms)","metadata":{}}]}